{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "## TOC\n",
    "- Student info\n",
    "- Important note\n",
    "- Special credits\n",
    "- Required imports and basic setup\n",
    "- Step 1: Loading the data\n",
    "   - 1.a: Saving the labels\n",
    "   - 1.b: Saving dictionary of file paths\n",
    "- Step 2: Data analysis\n",
    "   - 2.a: Distribtion of the training data\n",
    "   - 2.b: A deeper look at the training data\n",
    "   - 2.c: Feature extraction\n",
    "   - 2.d: The numerical representation\n",
    "   \n",
    "\n",
    "## Student info\n",
    "- **Name**: Bontinck Lennert\n",
    "- **StudentID**: 568702\n",
    "- **Affiliation**: VUB - Master Computer Science: AI\n",
    "\n",
    "## Important note\n",
    "In some codeblocks, the code might refer to variables from previous sections, in order to get accurate results code must be run top to bottom without skipping.\n",
    "\n",
    "## Special credits\n",
    "Some of the code used in this notebook is adopted or copied from the notebooks supplied in the Kaggle compition. A special thanks is given to Andries Rosseau for supplying us with this helpfull code.\n",
    "\n",
    "## Required imports and basic setup\n",
    "All required imports for this file are taken care of once using the following code block. Installing the required libraries is discussed in the README of this GitHub repository. Some basic setup for the used libraries is also taken care of here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pBddjUNSsFFX"
   },
   "outputs": [],
   "source": [
    "# standard packages used to handle files\n",
    "import sys\n",
    "import os \n",
    "import glob\n",
    "import time\n",
    "\n",
    "# commonly used library for data manipulation\n",
    "import pandas as pd\n",
    "\n",
    "# numerical\n",
    "import numpy as np\n",
    "\n",
    "# handle images - opencv\n",
    "import cv2\n",
    "\n",
    "# machine learning library\n",
    "import sklearn\n",
    "import sklearn.preprocessing\n",
    "\n",
    "# used to serialize python objects to disk and load them back to memory\n",
    "import pickle\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm as cm\n",
    "\n",
    "# helper functions\n",
    "import helpers\n",
    "\n",
    "# specific helper functions for feature extraction\n",
    "import features\n",
    "\n",
    "# tell matplotlib that we plot in a notebook and make images high(er) resolution\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png', 'svg'}\n",
    "\n",
    "# used for counting files\n",
    "import fnmatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets  location\n",
    "dataset_path = '../images/'\n",
    "# output location:\n",
    "output_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other path settings\n",
    "dataset_path_train = os.path.join(dataset_path, 'train')\n",
    "dataset_path_test = os.path.join(dataset_path, 'test')\n",
    "\n",
    "features_path = os.path.join(output_path, 'features')\n",
    "features_path_train = os.path.join(features_path, 'train')\n",
    "features_path_test = os.path.join(features_path, 'test')\n",
    "\n",
    "prediction_path = os.path.join(output_path, 'predictions')\n",
    "\n",
    "# filepatterns to write out features\n",
    "filepattern_descriptor_train = os.path.join(features_path_train, 'train_features_{}.pkl')\n",
    "filepattern_descriptor_test = os.path.join(features_path_test, 'test_features_{}.pkl')\n",
    "\n",
    "# create paths in case they don't exist:\n",
    "helpers.createPath(features_path)\n",
    "helpers.createPath(features_path_train)\n",
    "helpers.createPath(features_path_test)\n",
    "helpers.createPath(prediction_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Loading the data\n",
    "Before we can start exploring our data and making models we have to setup everything that is needed to access the data.\n",
    "\n",
    "The data is provided in the Kaggle compition and saved under a folder \"test\" and \"train\" inside the folder \"images\" which is saved in this files parent directory as set up in the previous basic setup step.\n",
    "\n",
    "### 1.a: Saving the labels\n",
    "The training data provided is saved inside a folder which name corresponds to the label of the data inside that folder. Thus getting the labels of the data is nothing more then getting all folder names inside the \"train\" folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_folder_paths = glob.glob(os.path.join(dataset_path_train,'*'))\n",
    "label_strings = np.sort(np.array([os.path.basename(path) for path in train_images_folder_paths]))\n",
    "amount_of_labels = label_strings.shape[0]\n",
    "\n",
    "print(\"Amount of classes (labels): \", amount_of_labels)\n",
    "print(\"\\nLabels: \", label_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.b: Saving dictionary of file paths\n",
    "Since loading all images of the train set into memory at once is hardly feasible, we simply collect all their filepaths and load them on demand. Therefore, we build a dictionary of the filepaths to all our train images, sorted by label. We do the same for our test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_paths = dict((label_string, helpers.getImgPaths(os.path.join(dataset_path_train, label_string))) \n",
    "                   for label_string in label_strings)\n",
    "\n",
    "test_paths = helpers.getImgPaths(dataset_path_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data analysis\n",
    "Before rigorously testing different models available it's important to take a look at the data that's supplied to us. This will not only validate the data is correctly loaded in the previous step but will also give us some hint as to what our data looks like, what it's distribution is...\n",
    "\n",
    "### 2.a: Distribtion of the training data\n",
    "This part is further discussed in the report of this project, in section: Data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retreiving data for plotting\n",
    "x = np.arange(amount_of_labels)\n",
    "x_heights = [len(fnmatch.filter(os.listdir(path), '[^.]*.*')) for path in train_images_folder_paths] \n",
    "\n",
    "# providing data to the plotting library\n",
    "fig, ax = plt.subplots()\n",
    "plt.bar(x, height=x_heights)\n",
    "\n",
    "# setting up details of the graph\n",
    "plt.xticks(x, label_strings)\n",
    "fig.autofmt_xdate()\n",
    "plt.ylabel('amount of samples provided')\n",
    "plt.title('Labeled data distribution')\n",
    "\n",
    "plt.savefig(\"../graphs/1-data_analysis-labeled_data_distribution.png\", facecolor=\"white\", edgecolor='none')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_amount_of_training_imgs = np.sum(x_heights)\n",
    "print('Total amount of training images: {}'.format(total_amount_of_training_imgs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.b: A deeper look at the training data\n",
    "This part is further discussed in the report of this project, in section: Deeper look at the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "fig, axes = plt.subplots(nrows=amount_of_labels, ncols=5, constrained_layout=True, figsize=(10, 10))\n",
    "\n",
    "[ax.get_xaxis().set_visible(False) for ax_row in axes for ax in ax_row]\n",
    "[ax.get_yaxis().set_visible(False) for ax_row in axes for ax in ax_row]\n",
    "\n",
    "for idx, label_string in enumerate(label_strings):\n",
    "    images = [cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB) for path in train_paths[label_string][:5]]\n",
    "\n",
    "    for colidx in range(5):\n",
    "        axes[idx, colidx].imshow(images[colidx])\n",
    "        if colidx == 2: # if this is the center column\n",
    "            axes[idx, colidx].set_title(label_string)\n",
    "            \n",
    "\n",
    "\n",
    "plt.savefig(\"../graphs/1-data_analysis-labeled_data_overview.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.c: Feature extraction\n",
    "This part is further discussed in the report of this project, in section: Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "current_image = cv2.imread(train_paths[\"chicken\"][0])\n",
    "corner_image, corner_coords = features.extractShiTomasiCorners(current_image, num_features=500, min_distance=20, visualize=True)    \n",
    "\n",
    "\n",
    "plt.imshow(cv2.cvtColor(corner_image, cv2.COLOR_BGR2RGB))\n",
    "plt.savefig(\"../graphs/1-data_analysis-POI.png\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.d: The numerical representation\n",
    "This part is further discussed in the report of this project, in section: Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptor_desired = 'sift'\n",
    "\n",
    "with open(filepattern_descriptor_train.format(descriptor_desired), 'rb') as pkl_file_train:\n",
    "    train_features_from_pkl = pickle.load(pkl_file_train)\n",
    "    \n",
    "print('Number of encoded train images: {}'.format(len(train_features_from_pkl)))\n",
    "\n",
    "with open(filepattern_descriptor_test.format(descriptor_desired), 'rb') as pkl_file_test:\n",
    "    test_features_from_pkl = pickle.load(pkl_file_test)\n",
    "        \n",
    "print('Number of encoded test images: {}'.format(len(test_features_from_pkl)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_points_per_image = 30\n",
    "\n",
    "clustered_codebook = helpers.createCodebook(train_features_from_pkl, codebook_size=amount_of_points_per_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode all train images \n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "for image_features in train_features_from_pkl:\n",
    "    bow_feature_vector = helpers.encodeImage(image_features.data, clustered_codebook)\n",
    "    train_data.append(bow_feature_vector)\n",
    "    train_labels.append(image_features.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Amoount of points available: \", len(train_features_from_pkl[0][2]))\n",
    "print(\"Amoount of points requested: \", len(train_data[0]))\n",
    "print(\"\\nTrain labels: \", train_labels[:5])\n",
    "print(\"Train data: \\n\", train_data[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert train labels to numerical representation\n",
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "label_encoder.fit(label_strings)\n",
    "train_labels_numerical = label_encoder.transform(train_labels)\n",
    "\n",
    "# loading in data as PD\n",
    "data = np.c_[train_data, train_labels_numerical]\n",
    "feature_names = [\"Feature \" + str(x + 1) for x in range(amount_of_points_per_image)]\n",
    "columns = np.append(feature_names, [\"target\"])\n",
    "pd_data = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "pd_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_data.hist(figsize = (16,16)) # figsize: (width,height)\n",
    "plt.savefig(\"../graphs/1-data_analysis-feature_representation.png\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation_matrix(df):\n",
    "    \"\"\"Takes a pandas dataframe as input\"\"\"\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(14,10))\n",
    "    plt.jet() # set the colormap to jet\n",
    "    cax = ax.matshow(df.corr(), vmin=-1, vmax=1)\n",
    "\n",
    "    ticks = list(range(len(df.columns)))\n",
    "    ax.set_xticks(ticks)\n",
    "    ax.set_yticks(ticks)\n",
    "\n",
    "    ax.set_xticklabels(df.columns, rotation=90, horizontalalignment='left')\n",
    "    ax.set_yticklabels(df.columns)\n",
    "    \n",
    "    fig.colorbar(cax, ticks=[-1.0,-0.75,-0.5,-0.25,0.0,0.25,0.5,0.75,1.0])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"../graphs/1-data_analysis-correlation_matrix.png\") \n",
    "    plt.show()\n",
    "    \n",
    "plot_correlation_matrix(pd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classification_example.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
