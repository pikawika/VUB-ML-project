% done
\part{Linear SVC}
\label{part:linear_svc}

%------------------------------------

\section{About this part}
\label{section:LinSVC_about_part}

In the previous part, three different kernels for SVC were explored.
Another kernel available for SVC is the \textit{linear kernel}.
However, there's also a separate model, \texttt{LinearSVC}, available as well.
The performance of the linear kernel and this separate model are explored in this part.
The Notebook corresponding with this part is \texttt{linear\_SVC.ipynb}.

%------------------------------------

\section{Scoring and methodology for fine-tuning}
\label{section:LinSVC_methodology}

The algorithms are tested and evaluated as the non-linear SVC from part \ref{part:svc}.
In order for MCLL scoring to work, a \texttt{predict\_proba} function should be available.
For \texttt{LinearSVC} this is not the case, it can, however, be implemented by wrapping it with Sci-Kit's \texttt{CalibratedClassifierCV}.
Arguably, this wrapping can influence the performance, however, the Kaggle competition also requires a \texttt{predict\_proba} function thus the wrapping is necessary and its performance impact should be taken into account.
Both balanced and non-balanced variant were considered, the received scores were comparable and the balanced variant is preferred and discussed.
A short discussion of the tried parameters and found results using \texttt{GridSearchCV} is listed here:
\begin{itemize}
    \item \texttt{SVC} with linear kernel:
    \begin{itemize}
        \item Tested C: 0.001, 0.01 , 0.1, 0.5, 1.0, 1.5, 3, 5, 10 and 100.
        \item Tested gamma: "scale", "auto", 0.001, 0.01 , 0.1, 0.5, 1.0, 1.5, 3, 5, 10 and 100.
        \item Found optima: C = 0.01 | gamma had no influence, 0.001 is chosen | SCV MCLL score of ± 1.56.
    \end{itemize}
    \item \texttt{LinearSVC}:
    \begin{itemize}
        \item Tested C: 0.001, 0.01 , 0.1, 0.5, 1.0, 1.5, 3, 5, 10 and 100.
        \item Tested penalty and loss: l1 and l2 | hinge and squared hinge.
        \item Tested dual: True and False.
        \item Found optima: C = 0.1 | penalty = l1 | dual = False | loss = squared hinge | SCV MCLL score of ± 1.63.
    \end{itemize}
\end{itemize}

%------------------------------------

\section{Linear is not the way to go}
\label{section:linsvc_optimal}

The SVC model with linear kernel performed better than the LinearSVC model.
Further fine-tuning around the found optima didn't gain any performance.
It is noted that LinearSVC often \textit{fitted quicker}, which perhaps explains it's existence.
Since the linear SVC approach performed worse then the optimal SVC found in part \ref{part:svc} it was not discussed in great detail and is not explored further.
During testing, the received MCLL score for the validation set was ± 1.60 and the SCV MCLL score was ± 1.55.
The received Kaggle score for the optimal linear SVC model is 1.59520.